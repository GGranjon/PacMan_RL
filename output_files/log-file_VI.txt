History of the utilities after each iteration of the value iteration algorithm.
The empty state utility stays at 0, but is changed at the end of the algorithm. 

Gamma : 0.25, threshold : 0.001

Iteration 0 : 

 0.00000  0.00000  0.00000  0.00000
 0.00000  0.00000  0.00000  0.00000
 0.00000  0.00000  0.00000  0.00000

Iteration 1 : 

-0.04000 -0.04000 -0.04000  1.00000
-0.04000  0.00000 -0.04000 -1.00000
-0.04000 -0.04000 -0.04000 -0.04000

Iteration 2 : 

-0.05000 -0.05000  0.15800  1.22400
-0.05000  0.00000 -0.05000 -0.82600
-0.05000 -0.05000 -0.05000 -0.05000

Iteration 3 : 

-0.05250 -0.01090  0.20750  1.27935
-0.05250  0.00000 -0.03030 -0.77710
-0.05250 -0.05250 -0.05250 -0.05250

Iteration 4 : 

-0.04480  0.00096  0.22030  1.29304
-0.05313  0.00000 -0.01869 -0.76432
-0.05313 -0.05313 -0.04869 -0.05313

Iteration 5 : 

-0.04226  0.00411  0.22365  1.29644
-0.05162  0.00000 -0.01551 -0.76097
-0.05328 -0.05239 -0.04639 -0.05317

Iteration 6 : 

-0.04153  0.00494  0.22449  1.29729
-0.05103  0.00000 -0.01468 -0.76012
-0.05297 -0.05190 -0.04574 -0.05312

Iteration 7 : 

-0.04133  0.00515  0.22470  1.29750
-0.05086  0.00000 -0.01447 -0.75991
-0.05283 -0.05174 -0.04556 -0.05310

Final utilities :

-0.04128  0.00520  0.22476  1.29756
-0.05081      nan -0.01442 -0.75986
-0.05279 -0.05170 -0.04552 -0.05309


Best actions per state :

 right  right  right     up
    up   None     up     up
    up  right     up   down
